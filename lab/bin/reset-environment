#!/bin/bash

module=$1

repository_path="/eks-workshop/repository"
manifests_path="/eks-workshop/manifests"
base_path="$manifests_path/base"

set -Eeuo pipefail

mkdir -p /eks-workshop

rm -rf $manifests_path

REPOSITORY_REF=${REPOSITORY_REF:-""}

if [ ! -z "${REPOSITORY_REF}" ]; then
  rm -rf $repository_path

  echo "Loading workshop repository..."

  git clone https://github.com/aws-samples/eks-workshop-v2.git $repository_path > /dev/null
  (cd $repository_path && git checkout "${REPOSITORY_REF}" > /dev/null)

  echo ""

  cp -R $repository_path/manifests $manifests_path
fi

echo "Resetting the environment, please wait"

if [ -f "/eks-workshop/hooks/cleanup.sh" ]; then
  bash /eks-workshop/hooks/cleanup.sh
fi

kubectl apply -k $base_path --prune --all \
  --prune-whitelist=autoscaling/v1/HorizontalPodAutoscaler \
  --prune-whitelist=core/v1/Service \
  --prune-whitelist=core/v1/ConfigMap \
  --prune-whitelist=apps/v1/Deployment \
  --prune-whitelist=apps/v1/StatefulSet \
  --prune-whitelist=core/v1/ServiceAccount \
  --prune-whitelist=core/v1/Secret \
  --prune-whitelist=core/v1/PersistentVolumeClaim \
  --prune-whitelist=scheduling.k8s.io/v1/PriorityClass \
  --prune-whitelist=networking.k8s.io/v1/Ingress > /dev/null

echo "Waiting for application to become ready..."

sleep 10

kubectl wait --for=condition=available --timeout=240s deployments -l app.kubernetes.io/created-by=eks-workshop -A > /dev/null
kubectl wait --for=condition=Ready --timeout=240s pods -l app.kubernetes.io/created-by=eks-workshop -A > /dev/null

# Addons
mkdir -p /eks-workshop/terraform
cp $manifests_path/terraform/base.tf /eks-workshop/terraform

export TF_VAR_eks_cluster_id="$EKS_CLUSTER_NAME"


RESOURCES_PRECREATED=${RESOURCES_PRECREATED:-""}

echo "Cleaning up addons..."

tf_dir=$(realpath --relative-to='$PWD' '/eks-workshop/terraform')

terraform -chdir="$tf_dir" init -upgrade > /tmp/terraform-destroy-init.log
terraform -chdir="$tf_dir" destroy --auto-approve > /tmp/terraform-destroy.log

rm -rf /eks-workshop/terraform/addon*.tf

rm -rf /eks-workshop/hooks
rm -rf ~/environment/lab

if [ ! -z "$module" ]; then
  module_path="$manifests_path/modules/$module"

  if [ -f "$module_path/.workshop/cleanup.sh" ]; then
    mkdir -p /eks-workshop/hooks
    cp "$module_path/.workshop/cleanup.sh" /eks-workshop/hooks
  fi

  if [ -f "$module_path/.workshop/addon.tf" ]; then
    echo "Applying lab addons..."

    cp "$module_path/.workshop/addon.tf" /eks-workshop/terraform

    if [ "$RESOURCES_PRECREATED" != "true" ]; then
      if [ -f "$module_path/.workshop/addon_infrastructure.tf" ]; then
        cp "$module_path/.workshop/addon_infrastructure.tf" /eks-workshop/terraform
      fi
    fi

    terraform -chdir="$tf_dir" init -upgrade > /tmp/terraform-apply-init.log
    terraform -chdir="$tf_dir" apply -refresh=false --auto-approve > /tmp/terraform-apply.log
  fi

  if [ -f "$module_path/.workshop/kustomization.yaml" ]; then
    echo "Applying lab manifests..."

    kubectl apply -k "$module_path/.workshop" > /dev/null
  fi

  mkdir -p ~/environment/lab

  cp -R $module_path/* ~/environment/lab
fi

terraform -chdir="$tf_dir" output -json | jq -r '.environment.value | select(. != null)' > ~/.bashrc.d/workshop-env.bash

# Node groups
expected_size_config="$EKS_DEFAULT_MNG_MIN $EKS_DEFAULT_MNG_MAX $EKS_DEFAULT_MNG_DESIRED"

mng_size_config=$(aws eks describe-nodegroup --cluster-name $EKS_CLUSTER_NAME --nodegroup-name $EKS_DEFAULT_MNG_NAME | jq -r '.nodegroup.scalingConfig | "\(.minSize) \(.maxSize) \(.desiredSize)"')

if [[ "$mng_size_config" != "$expected_size_config" ]]; then
  echo "Setting EKS Node Group back to initial sizing..."

  aws eks update-nodegroup-config --cluster-name $EKS_CLUSTER_NAME --nodegroup-name $EKS_DEFAULT_MNG_NAME \
    --scaling-config desiredSize=$EKS_DEFAULT_MNG_DESIRED,minSize=$EKS_DEFAULT_MNG_MIN,maxSize=$EKS_DEFAULT_MNG_MAX > /dev/null
  aws eks wait nodegroup-active --cluster-name $EKS_CLUSTER_NAME --nodegroup-name $EKS_DEFAULT_MNG_NAME

  sleep 10
fi

asg_size_config=$(aws autoscaling describe-auto-scaling-groups --filters "Name=tag:eks:nodegroup-name,Values=$EKS_DEFAULT_MNG_NAME" | jq -r '.AutoScalingGroups[0] | "\(.MinSize) \(.MaxSize) \(.DesiredCapacity)"')

if [[ "$asg_size_config" != "$expected_size_config" ]]; then
  echo "Setting ASG back to initial sizing..."

  export ASG_NAME=$(aws autoscaling describe-auto-scaling-groups --filters "Name=tag:eks:nodegroup-name,Values=$EKS_DEFAULT_MNG_NAME" --query "AutoScalingGroups[0].AutoScalingGroupName" --output text)
  aws autoscaling update-auto-scaling-group \
      --auto-scaling-group-name $ASG_NAME \
      --min-size $EKS_DEFAULT_MNG_MIN \
      --max-size $EKS_DEFAULT_MNG_MAX \
      --desired-capacity $EKS_DEFAULT_MNG_DESIRED
fi

EXIT_CODE=0

timeout -s TERM 300 bash -c \
    'while [[ $(kubectl get nodes -l workshop-default=yes -o json | jq -r ".items | length") -gt 3 ]];\
    do sleep 30;\
    done' || EXIT_CODE=$?

if [ $EXIT_CODE -ne 0 ]; then
  >&2 echo "Error: Nodes did not scale back to 3"
  exit 1
fi

# Recycle workload pods in case stateful pods got restarted
kubectl delete pod -l app.kubernetes.io/created-by=eks-workshop -l app.kubernetes.io/component=service -A > /dev/null

kubectl wait --for=condition=Ready --timeout=240s pods -l app.kubernetes.io/created-by=eks-workshop -A > /dev/null

# Finished
echo 'Environment is ready'
